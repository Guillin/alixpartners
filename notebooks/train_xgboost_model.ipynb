{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed of random number generator, which is useful for creating simulations \n",
    "# or random objects that can be reproduced.\n",
    "import random\n",
    "SEED=3\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train Data\n",
    "train = pd.read_csv('../data/processed/train_aggr.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34540, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fecha_venta_norm'] = pd.to_datetime(train['fecha_venta_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fecha_venta_norm'] = train['fecha_venta_norm'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos los meses que consideramos buenos para el entrenamiento (11 y 12)\n",
    "train = train[train.fecha_venta_norm.isin([#date(2012, 11, 1),\n",
    "                                                 date(2012, 12, 1),\n",
    "                                                #date(2013, 11, 1), \n",
    "                                                 date(2013, 12, 1), \n",
    "                                                 #date(2014, 11, 1)\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['id_pos','canal', 'competidores',\n",
    "       'ingreso_mediana', 'densidad_poblacional',\n",
    "       'pct_0a5', 'pct_5a9', 'pct_10a14', 'pct_15a19', 'pct_20a24',\n",
    "       'pct_25a29', 'pct_30a34', 'pct_35a39', 'pct_40a44', 'pct_45a49',\n",
    "       'pct_50a54', 'pct_55a59', 'pct_60a64', 'pct_65a69', 'pct_70a74',\n",
    "       'pct_75a79', 'pct_80a84', 'pct_85ainf', 'pct_bachelors',\n",
    "       'pct_doctorados', 'pct_secundario', 'pct_master', 'pct_bicicleta',\n",
    "       'pct_omnibus', 'pct_subtes', 'pct_taxi', 'pct_caminata',\n",
    "       'mediana_valor_hogar', 'unidades']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[predictors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encode catvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(train['canal'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['canal'] = le.transform(train['canal'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.iloc[:,:-1],train.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =========================================================================================================\n",
    "# \n",
    "#  Booster Parameters \n",
    "#\n",
    "# n_estimators\n",
    "#    - The number of sequential trees to be modeled\n",
    "#    - Though GBM is fairly robust at higher number of trees but it can still overfit at a point.\n",
    "#\n",
    "# max_depth [default=6]\n",
    "#    - The maximum depth of a tree.\n",
    "#    - Used to control over-fitting as higher depth will allow model to learn relations very pecific to a particular sample.\n",
    "#    - Typical values: 3-10\n",
    "#\n",
    "# min_child_weight [default=1]\n",
    "#    - Defines the minimum sum of weights of all observations required in a child.\n",
    "#    - This is similar to min_child_leaf in GBM but not exactly.\n",
    "#      This refers to min sum of weightsof observations while GBM has min number of observations.\n",
    "#    - Used to control over-fitting. Higher values prevent a model from learning relations\n",
    "#      which might be highly specific to the particular sample selected for a tree.\n",
    "#    - Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "#\n",
    "# eta : learning rate\n",
    "#   - Makes the model more robust by shrinking the weights on each step\n",
    "#   - Typical final values to be used: 0.01-0.2\n",
    "#\n",
    "# gamma [default=0]\n",
    "#\n",
    "#    - A node is split only when the resulting split gives a positive reduction in the loss function.\n",
    "#    - Gamma specifies the minimum loss reduction required to make a split.\n",
    "#    - Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "#\n",
    "# subsample [default=1]\n",
    "#     - Denotes the fraction of observations to be randomly samples for each tree.\n",
    "#     - Lower values make the algorithm more conservative and prevents overfitting but too small values\n",
    "#       might lead to under-fitting.\n",
    "#     - Typical values: 0.5-1\n",
    "#\n",
    "# colsample_bytree [default=1]\n",
    "#     - Denotes the fraction of columns to be randomly samples for each tree.\n",
    "#     - Typical values: 0.5-1\n",
    "#\n",
    "# alpha [default=0]\n",
    "#     - L1 regularization term on weight (analogous to Lasso regression)\n",
    "#     - Can be used in case of very high dimensionality so that the algorithm runs faster when implemented\n",
    "#\n",
    "# scale_pos_weight [default=1]\n",
    "#     A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence.\n",
    "#\n",
    "## ===========================================================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of trees (estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold cross validation is more accurate than using a single validation set\n",
    "cv_folds = 5\n",
    "early_stopping_rounds = 50\n",
    "model = xgb.XGBRegressor(seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = model.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'importance_type': 'gain',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 100,\n",
       " 'nthread': 1,\n",
       " 'objective': 'reg:linear',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 3,\n",
       " 'subsample': 1,\n",
       " 'verbosity': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train on GPU\n",
    "xgb_param['objective'] = 'reg:squarederror'\n",
    "xgb_param['gpu_id'] = 0\n",
    "xgb_param['max_bin'] = 16\n",
    "xgb_param['tree_method'] = 'gpu_hist'\n",
    "xgb_param['learning_rate'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
      "0         26.915981       0.054026      26.916026      0.217875\n",
      "1         26.647311       0.053501      26.647438      0.217424\n",
      "2         26.381565       0.052956      26.381764      0.216905\n",
      "3         26.119152       0.052414      26.119396      0.216394\n",
      "4         25.861280       0.051861      25.861614      0.215815\n",
      "5         25.606877       0.051326      25.607226      0.215276\n",
      "6         25.356213       0.050859      25.356646      0.214734\n",
      "7         25.108317       0.050328      25.108745      0.214277\n",
      "8         24.863579       0.049815      24.864052      0.213767\n",
      "9         24.621905       0.049360      24.622397      0.213322\n",
      "10        24.383354       0.049013      24.383942      0.212760\n",
      "11        24.148663       0.048543      24.149362      0.212216\n",
      "12        23.917462       0.048028      23.918044      0.211386\n",
      "13        23.689440       0.047471      23.689941      0.210870\n",
      "14        23.466430       0.047039      23.466871      0.209874\n",
      "15        23.246638       0.046603      23.247237      0.209170\n",
      "16        23.030328       0.045949      23.030928      0.208220\n",
      "17        22.816803       0.045412      22.817655      0.207409\n",
      "18        22.606364       0.044904      22.607450      0.206276\n",
      "19        22.399138       0.044454      22.400600      0.205649\n",
      "20        22.195881       0.044299      22.197214      0.204676\n",
      "21        21.996240       0.043747      21.997622      0.204101\n",
      "22        21.799805       0.043115      21.801162      0.203431\n",
      "23        21.606385       0.042882      21.607958      0.202359\n",
      "24        21.416981       0.042574      21.418407      0.201306\n",
      "25        21.231931       0.041991      21.233506      0.200727\n",
      "26        21.049995       0.041698      21.051456      0.199988\n",
      "27        20.871426       0.041298      20.873338      0.199570\n",
      "28        20.696285       0.040905      20.698143      0.199441\n",
      "29        20.525094       0.041212      20.527209      0.198953\n",
      "..              ...            ...            ...           ...\n",
      "164       13.126880       0.079139      13.155744      0.301618\n",
      "165       13.122128       0.079217      13.151277      0.301772\n",
      "166       13.117609       0.079450      13.147016      0.301760\n",
      "167       13.113243       0.079575      13.142962      0.301831\n",
      "168       13.108984       0.079750      13.139172      0.302035\n",
      "169       13.104884       0.079882      13.135298      0.302121\n",
      "170       13.100880       0.080004      13.131666      0.302193\n",
      "171       13.097089       0.080117      13.128046      0.302245\n",
      "172       13.093363       0.080273      13.124649      0.302374\n",
      "173       13.089927       0.080379      13.121365      0.302372\n",
      "174       13.086547       0.080456      13.118180      0.302483\n",
      "175       13.083338       0.080534      13.115157      0.302484\n",
      "176       13.080274       0.080569      13.112324      0.302553\n",
      "177       13.077391       0.080655      13.109727      0.302662\n",
      "178       13.074527       0.080744      13.107291      0.302689\n",
      "179       13.071873       0.080722      13.104994      0.303003\n",
      "180       13.069389       0.080593      13.102650      0.303316\n",
      "181       13.067048       0.080459      13.100623      0.303544\n",
      "182       13.064791       0.080416      13.098749      0.303689\n",
      "183       13.062855       0.080425      13.097126      0.303928\n",
      "184       13.061162       0.080517      13.095732      0.303915\n",
      "185       13.059730       0.080762      13.094481      0.303797\n",
      "186       13.058405       0.081075      13.093543      0.303628\n",
      "187       13.057317       0.081428      13.092677      0.303370\n",
      "188       13.056394       0.081815      13.092103      0.303085\n",
      "189       13.055592       0.082134      13.091428      0.302811\n",
      "190       13.054962       0.082289      13.091214      0.302711\n",
      "191       13.054407       0.082339      13.091007      0.302589\n",
      "192       13.053896       0.082390      13.090837      0.302527\n",
      "193       13.053515       0.082384      13.090699      0.302486\n",
      "\n",
      "[194 rows x 4 columns]\n",
      "Optimal number of trees (estimators) is 194\n"
     ]
    }
   ],
   "source": [
    "cvresult = xgb.cv(params=xgb_param, dtrain=data_dmatrix, num_boost_round = 1000, nfold = cv_folds, metrics = 'mae', early_stopping_rounds = early_stopping_rounds, seed = SEED)\n",
    "print(cvresult)\n",
    "print (\"Optimal number of trees (estimators) is %i\" % cvresult.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth & min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(objective = 'reg:squarederror')\n",
    "model.set_params(gpu_id = 0)\n",
    "model.set_params(max_bin= 16)\n",
    "\n",
    "model.set_params(learning_rate = 0.01)\n",
    "model.set_params(n_estimators=194)\n",
    "model.set_params(tree_method='gpu_hist')\n",
    "\n",
    "\n",
    "param_test1 = {\n",
    "'max_depth': [i for i in range(2,8,1)],\n",
    "'min_child_weight': [i for i in range(1,6,1)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1 = GridSearchCV(estimator = model, param_grid = param_test1, scoring = 'neg_mean_absolute_error',  iid = False, cv = cv_folds, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "res =gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 2}\n",
      "-12.903912042445237\n"
     ]
    }
   ],
   "source": [
    "#print gsearch1.grid_scores_\n",
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(max_depth = 7)\n",
    "model.set_params(min_child_weight = 2)\n",
    "\n",
    "param_test2 = {\n",
    "'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   60.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n",
       "       importance_type='gain', learning_rate=0.01, max_bin=16,\n",
       "       max_delta_step=0, max_depth=7, min_child_weight=2, missing=None,\n",
       "       n_estimators=1...1, scale_pos_weight=1, seed=3, silent=None, subsample=1,\n",
       "       tree_method='gpu_hist', verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2 = GridSearchCV(estimator = model, param_grid = param_test2, scoring = 'neg_mean_absolute_error',  iid = False, cv = cv_folds, verbose = 1)\n",
    "gsearch2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "-12.903912042445237\n"
     ]
    }
   ],
   "source": [
    "print(gsearch2.best_params_)\n",
    "print(gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recal number of trees (estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold cross validation is more accurate than using a single validation set\n",
    "cv_folds = 5\n",
    "early_stopping_rounds = 50\n",
    "model = xgb.XGBRegressor(seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = model.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train on GPU\n",
    "xgb_param['objective'] = 'reg:squarederror'\n",
    "xgb_param['gpu_id'] = 0\n",
    "xgb_param['max_bin'] = 16\n",
    "xgb_param['tree_method'] = 'gpu_hist'\n",
    "xgb_param['learning_rate'] = 0.01\n",
    "xgb_param['gamma'] = 0.0\n",
    "xgb_param['max_depth'] = 7\n",
    "xgb_param['min_child_weight'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
      "0         26.917710       0.053999      26.917679      0.218485\n",
      "1         26.650690       0.053441      26.650699      0.218459\n",
      "2         26.386586       0.052918      26.386501      0.218486\n",
      "3         26.125785       0.052432      26.125932      0.217811\n",
      "4         25.869141       0.051933      25.869835      0.217685\n",
      "5         25.616086       0.051461      25.616895      0.217627\n",
      "6         25.366524       0.051067      25.367503      0.217386\n",
      "7         25.119700       0.050521      25.121227      0.217174\n",
      "8         24.876011       0.050075      24.877820      0.216975\n",
      "9         24.635239       0.049586      24.637687      0.216456\n",
      "10        24.397578       0.049246      24.400493      0.216270\n",
      "11        24.163297       0.048797      24.166944      0.215834\n",
      "12        23.932572       0.048398      23.937054      0.215733\n",
      "13        23.705100       0.047991      23.710760      0.215795\n",
      "14        23.481435       0.047523      23.488409      0.215955\n",
      "15        23.261050       0.047228      23.269477      0.215412\n",
      "16        23.043953       0.046719      23.053971      0.214956\n",
      "17        22.829976       0.046178      22.841173      0.214321\n",
      "18        22.618824       0.045667      22.632220      0.213008\n",
      "19        22.410875       0.045216      22.426099      0.211929\n",
      "20        22.206360       0.044663      22.223960      0.211017\n",
      "21        22.005062       0.044315      22.024354      0.209556\n",
      "22        21.807007       0.043547      21.829369      0.207724\n",
      "23        21.611981       0.042927      21.637091      0.206548\n",
      "24        21.420059       0.042098      21.448420      0.205619\n",
      "25        21.231670       0.041516      21.263743      0.204266\n",
      "26        21.046601       0.040938      21.081939      0.203978\n",
      "27        20.864857       0.040778      20.903788      0.203182\n",
      "28        20.686587       0.040363      20.729345      0.203042\n",
      "29        20.511581       0.040285      20.558476      0.202898\n",
      "..              ...            ...            ...           ...\n",
      "179       12.136259       0.103289      12.965843      0.327744\n",
      "180       12.128710       0.102060      12.962602      0.328134\n",
      "181       12.122299       0.102791      12.959853      0.328153\n",
      "182       12.114562       0.103218      12.956562      0.328619\n",
      "183       12.107806       0.103151      12.953932      0.328843\n",
      "184       12.100560       0.103629      12.951302      0.328325\n",
      "185       12.094684       0.103990      12.949212      0.328652\n",
      "186       12.088507       0.105025      12.947033      0.328417\n",
      "187       12.082159       0.105472      12.944993      0.328382\n",
      "188       12.076600       0.106269      12.943166      0.328384\n",
      "189       12.071325       0.106659      12.941422      0.328974\n",
      "190       12.066058       0.106260      12.939631      0.329455\n",
      "191       12.060021       0.106899      12.938291      0.328919\n",
      "192       12.053759       0.106614      12.936468      0.328539\n",
      "193       12.048366       0.107639      12.935135      0.328312\n",
      "194       12.042990       0.108188      12.933679      0.328070\n",
      "195       12.036772       0.108402      12.932071      0.328426\n",
      "196       12.032370       0.109181      12.931026      0.328672\n",
      "197       12.028241       0.109446      12.930132      0.328591\n",
      "198       12.023811       0.110992      12.928946      0.328297\n",
      "199       12.019281       0.112214      12.928260      0.328379\n",
      "200       12.013610       0.113295      12.926980      0.328316\n",
      "201       12.009836       0.113885      12.926580      0.328536\n",
      "202       12.003949       0.113928      12.925640      0.328455\n",
      "203       11.998871       0.115148      12.925203      0.328494\n",
      "204       11.994394       0.115935      12.924726      0.328719\n",
      "205       11.990297       0.115481      12.924313      0.328819\n",
      "206       11.985629       0.116075      12.923994      0.328282\n",
      "207       11.981114       0.117723      12.923872      0.328594\n",
      "208       11.976706       0.116759      12.923059      0.328640\n",
      "\n",
      "[209 rows x 4 columns]\n",
      "Optimal number of trees (estimators) is 209\n"
     ]
    }
   ],
   "source": [
    "cvresult = xgb.cv(params=xgb_param, dtrain=data_dmatrix, num_boost_round = 1000, nfold = cv_folds, metrics = 'mae', early_stopping_rounds = early_stopping_rounds, seed = SEED)\n",
    "print(cvresult)\n",
    "print (\"Optimal number of trees (estimators) is %i\" % cvresult.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N_estimators = 93 sigue siendo el mejor valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample & colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(objective = 'reg:squarederror')\n",
    "model.set_params(gpu_id = 0)\n",
    "model.set_params(max_bin= 16)\n",
    "model.set_params(tree_method='gpu_hist')\n",
    "model.set_params(learning_rate = 0.01)\n",
    "model.set_params(n_estimators=209)\n",
    "model.set_params(max_depth = 7)\n",
    "model.set_params(min_child_weight = 2)\n",
    "model.set_params(gamma = 0.0)\n",
    "\n",
    "\n",
    "\n",
    "param_test3 = {\n",
    "'subsample' : [i/10.0 for i in range(6,11)],\n",
    "'colsample_bytree' : [i/10.0 for i in range(6,11)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_xgb_params of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0.0, gpu_id=0,\n",
       "       importance_type='gain', learning_rate=0.01, max_bin=16,\n",
       "       max_delta_step=0, max_depth=7, min_child_weight=2, missing=None,\n",
       "       n_estimators=209, n_jobs=1, nthread=None,\n",
       "       objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=3, silent=None, subsample=1,\n",
       "       tree_method='gpu_hist', verbosity=1)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0.0, gpu_id=0,\n",
       "       importance_type='gain', learning_rate=0.01, max_bin=16,\n",
       "       max_delta_step=0, max_depth=7, min_child_weight=2, missing=None,\n",
       "       n_estimators...1, scale_pos_weight=1, seed=3, silent=None, subsample=1,\n",
       "       tree_method='gpu_hist', verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'subsample': [0.6, 0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3 = GridSearchCV(estimator = model, param_grid = param_test3, scoring = 'neg_mean_absolute_error',  iid = False, cv = cv_folds, verbose = 1)\n",
    "gsearch3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'subsample': 0.8}\n",
      "-12.854480665766213\n"
     ]
    }
   ],
   "source": [
    "print(gsearch3.best_params_)\n",
    "print(gsearch3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(objective = 'reg:squarederror')\n",
    "model.set_params(gpu_id = 0)\n",
    "model.set_params(max_bin= 16)\n",
    "model.set_params(tree_method='gpu_hist')\n",
    "model.set_params(learning_rate = 0.01)\n",
    "model.set_params(n_estimators=209)\n",
    "model.set_params(max_depth = 7)\n",
    "model.set_params(min_child_weight = 2)\n",
    "model.set_params(colsample_bytree = 1.0)\n",
    "model.set_params(subsample = 0.8)\n",
    "model.set_params(gamma = 0.0)\n",
    "\n",
    "param_test4 = {\n",
    "'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1.0, gamma=0.0, gpu_id=0,\n",
       "       importance_type='gain', learning_rate=0.01, max_bin=16,\n",
       "       max_delta_step=0, max_depth=7, min_child_weight=2, missing=None,\n",
       "       n_estimato... scale_pos_weight=1, seed=3, silent=None,\n",
       "       subsample=0.8, tree_method='gpu_hist', verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'reg_alpha': [1e-05, 0.01, 0.1, 1, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4 = GridSearchCV(estimator = model, param_grid = param_test4, scoring = 'neg_mean_absolute_error',  iid = False, cv = cv_folds, verbose = 1)\n",
    "gsearch4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 100}\n",
      "-12.849600719385526\n"
     ]
    }
   ],
   "source": [
    "print(gsearch4.best_params_)\n",
    "print(gsearch4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1.0, gamma=0.0, gpu_id=0,\n",
       "       importance_type='gain', learning_rate=0.01, max_bin=16,\n",
       "       max_delta_step=0, max_depth=7, min_child_weight=2, missing=None,\n",
       "       n_estimators=209, n_jobs=1, nthread=None,\n",
       "       objective='reg:squarederror', random_state=0, reg_alpha=100,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=3, silent=None,\n",
       "       subsample=0.8, tree_method='gpu_hist', verbosity=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(objective = 'reg:squarederror')\n",
    "model.set_params(gpu_id = 0)\n",
    "model.set_params(max_bin= 16)\n",
    "model.set_params(tree_method='gpu_hist')\n",
    "model.set_params(learning_rate = 0.01)\n",
    "model.set_params(n_estimators=209)\n",
    "model.set_params(max_depth = 7)\n",
    "model.set_params(min_child_weight = 2)\n",
    "model.set_params(colsample_bytree = 1.0)\n",
    "model.set_params(subsample = 0.8)\n",
    "model.set_params(gamma = 0.0)\n",
    "model.set_params(reg_alpha = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1.0, gamma=0.0, gpu_id=0,\n",
       "       importance_type='gain', learning_rate=0.01, max_bin=16,\n",
       "       max_delta_step=0, max_depth=7, min_child_weight=2, missing=None,\n",
       "       n_estimators=209, n_jobs=1, nthread=None,\n",
       "       objective='reg:squarederror', random_state=0, reg_alpha=100,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=3, silent=None,\n",
       "       subsample=0.8, tree_method='gpu_hist', verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE unidades:  13.004424819618848\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE unidades: \",mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean unidades pred:  23.99622\n"
     ]
    }
   ],
   "source": [
    "print(\"mean unidades pred: \", np.mean(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median unidades pred:  20.809826\n"
     ]
    }
   ],
   "source": [
    "print(\"median unidades pred: \", np.median(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xgboost GPU(env)",
   "language": "python",
   "name": "xgbgpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
